<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>RoboMIND2.0</title>
  <link rel="icon" href="./figs/logo.png" type="image/png">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
  <link rel="stylesheet" href="style.css">
  <style>
    /* GIF 阵列样式 */
    .gif-gallery-section {
      margin: 10px 0;
    }
    .gif-task-row {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5px;
      margin-bottom: 0.5px;
    }
    .gif-task-item {
      flex: 0 0 calc(16.666% - 4px); /* 固定宽度（6列），精准减去gap值，确保填满整行 */
      box-sizing: border-box;
      padding: 0; /* 清除内边距 */
      margin: 0; /* 清除外边距 */
    }
    .gif-task-item img {
      width: 100%;
      height: auto;
      border-radius: 4px;
      border: 1px solid #eee;
    }
    /* 响应式适配 */
    @media (max-width: 1200px) {
      .gif-task-item {
        min-width: calc(33.333% - 10px); /* 屏幕变小时每行3个 */
      }
    }
    @media (max-width: 768px) {
      .gif-task-item {
        min-width: calc(50% - 10px); /* 手机端每行2个 */
      }
    }
  </style>
</head>

<body>
  <div class="toc">
    <h3>Content</h3>
    <hr>
    <ul>
      <li><a href="#abstract">Abstract</a></li>
      <li><a href="#collection-platform">Collection Platform</a></li>
      <li><a href="#realworld-setup">Real-world Setup</a></li>
      <li><a href="#realworld-results">Real-world Experiments</a></li>
      <li><a href="#dual-system-experiments">Dual System Experiments</a></li>
      <!-- <li class="toc-subsection"><a href="#training-in-sim">Training in Sim</a></li> -->
    </ul>
  </div>

  <div class="main-content">
    <div class="hero-text" style="font-size: 100px; text-align: center; margin-bottom: -10px;">RoboMIND2.0</div>
    <div class="sub-hero-text" style="text-align: center;">A Multimodal, Bimanual Mobile
Manipulation Dataset for Generalizable Embodied Intelligence</div>

    <!-- add authors -->
    <div class="authors" style="text-align: center; color: #000000;">
      <div class="author-block" style="font-weight: bold; line-height: 1.6;">
        Chengkai Hou<sup>1,2,*,&#8225;</sup>, Kun Wu<sup>1,*,&#8225;</sup>, Jiaming Liu<sup>2,*,&#8225;</sup>, Zhengping Che<sup>1,*,&#8224;</sup>, Di Wu<sup>1,2,*</sup>,<br>
        Fei Liao<sup>1,2,*</sup>, Guangrun Li<sup>1,2,*</sup>, Jingyang He<sup>1,2,*</sup>, Qiuxuan Feng<sup>1,2,*</sup>, Zhao Jin<sup>1,*</sup>,<br>
        Chenyang Gu<sup>2</sup>, Zhuoyang Liu<sup>2</sup>, Nuowei Han<sup>2</sup>, Xiangju Mi<sup>2</sup>, Yaoxu Lv<sup>2</sup>,<br>
        Yankai Fu<sup>2</sup>, Gaole Dai<sup>2</sup>, Langzhe Gu<sup>2</sup>, Tao Li<sup>1</sup>, Yuheng Zhang<sup>1</sup>, Xinhua Wang<sup>1</sup>,<br>
        Shichao Fan<sup>1</sup>, Yixue Zhang<sup>1</sup>, Meng Li<sup>1</sup>, Zhen Zhao<sup>1</sup>, Ning Liu<sup>1</sup>,<br>
        Zhiyuan Xu<sup>1</sup>, Pei Ren<sup>1</sup>, Junjie Ji<sup>1</sup>, Haonan Liu<sup>1</sup>,<br>
        Kuan Cheng<sup>2</sup>, Shanghang Zhang<sup>2,&#9993;</sup>, Jian Tang<sup>1,&#9993;</sup>
      </div>

      <div class="affiliation" style="font-weight: normal; margin-top: 8px; line-height: 1.5;">
        <sup>1</sup>Beijing Innovation Center of Humanoid Robotics&nbsp;&nbsp;
        <sup>2</sup>School of Computer Science, Peking University
      </div>

      <div class="affiliation" style="font-size: 14px; font-weight: normal; margin-top: 6px; line-height: 1.4;">
        <span><sup>*</sup>Equal contribution</span>&nbsp;&nbsp;
        <span><sup>&#8224;</sup>Project lead</span>&nbsp;&nbsp;
        <span><sup>&#8225;</sup>Co-first Core authors</span>&nbsp;&nbsp;
        <span><sup>&#9993;</sup>Corresponding authors</span>
      </div>
    </div>
    <video id="teaser-video" width="100%" height="100%" controls muted playsinline autoplay preload="metadata">
      <source src="https://github.com/log2r/RoboMIND2.0/releases/download/attachment/teaser_video.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>

    <div class="links-block">
      <a href="https://arxiv.org/pdf/2512.24653" target="_blank">[<strong>pdf</strong>]</a>
      <a href="https://arxiv.org/abs/2512.24653" target="_blank">[<strong>arxiv</strong>]</a>
      <a href="https://modelscope.cn/datasets/X-Humanoid/RoboMIND2.0/" target="_blank">[<strong>data</strong>]</a>
    </div>

    <!-- ===================== 新增的GIF阵列区域 ===================== -->
    <div class="gif-gallery-section">
      <h2 style="font-size: 24px; text-align: center; margin: 30px 0;">Dataset Overview</h2>
      
      <!-- Franka 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/franka/task1/camera_front.gif" alt="Franka Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/franka/task2/camera_front.gif" alt="Franka Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/franka/task3/camera_front.gif" alt="Franka Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/franka/task4/camera_front.gif" alt="Franka Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/franka/task5/camera_front.gif" alt="Franka Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/franka/task6/camera_front.gif" alt="Franka Task 6">
        </div>
      </div>

      <!-- UR 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/ur/task1/camera_front.gif" alt="UR Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ur/task2/camera_front.gif" alt="UR Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ur/task3/camera_front.gif" alt="UR Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ur/task4/camera_front.gif" alt="UR Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ur/task5/camera_front.gif" alt="UR Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ur/task6/camera_front.gif" alt="UR Task 6">
        </div>
      </div>

      <!-- AGX 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/agx/task1/camera_front.gif" alt="AGX Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agx/task2/camera_front.gif" alt="AGX Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agx/task3/camera_front.gif" alt="AGX Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agx/task4/camera_front.gif" alt="AGX Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agx/task5/camera_front.gif" alt="AGX Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agx/task6/camera_front.gif" alt="AGX Task 6">
        </div>
      </div>

      <!-- Agilex Mobile 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task1/camera_front.gif" alt="Agilex Mobile Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task2/camera_front.gif" alt="Agilex Mobile Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task3/camera_front.gif" alt="Agilex Mobile Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task4/camera_front.gif" alt="Agilex Mobile Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task5/camera_front.gif" alt="Agilex Mobile Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/agilex_mobile/task6/camera_front.gif" alt="Agilex Mobile Task 6">
        </div>
      </div>

      <!-- ARK 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/ark/task1/camera_front.gif" alt="ARK Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark/task2/camera_front.gif" alt="ARK Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark/task3/camera_front.gif" alt="ARK Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark/task4/camera_front.gif" alt="ARK Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark/task5/camera_front.gif" alt="ARK Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark/task6/camera_front.gif" alt="ARK Task 6">
        </div>
      </div>

      <!-- ARK Mobile 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task1/camera_front.gif" alt="ARK Mobile Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task2/camera_front.gif" alt="ARK Mobile Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task3/camera_front.gif" alt="ARK Mobile Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task4/camera_front.gif" alt="ARK Mobile Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task5/camera_front.gif" alt="ARK Mobile Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/ark_mobile/task6/camera_front.gif" alt="ARK Mobile Task 6">
        </div>
      </div>

      <!-- Tienkung 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task1/camera_front.gif" alt="Tienkung Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task2/camera_front.gif" alt="Tienkung Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task3/camera_front.gif" alt="Tienkung Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task4/camera_front.gif" alt="Tienkung Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task5/camera_front.gif" alt="Tienkung Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tienkung/task6/camera_front.gif" alt="Tienkung Task 6">
        </div>
      </div>

      <!-- Tianyi 机器人 -->
      <div class="gif-task-row">
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task1/camera_front.gif" alt="Tianyi Task 1">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task2/camera_front.gif" alt="Tianyi Task 2">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task3/camera_front.gif" alt="Tianyi Task 3">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task4/camera_front.gif" alt="Tianyi Task 4">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task5/camera_front.gif" alt="Tianyi Task 5">
        </div>
        <div class="gif-task-item">
          <img src="./gifs/tianyi/task6/camera_front.gif" alt="Tianyi Task 6">
        </div>
      </div>
    </div>
    <!-- ===================== GIF阵列区域结束 ===================== -->

    <div class="tagline" id="abstract">Abstract.</div>
    <div class="section">
      <p>
        While data-driven imitation learning has revolutionized robotic manipulation, current approaches remain constrained by the scarcity of large-scale, diverse real-world demonstrations.
        Consequently, the ability of existing models to generalize across long-horizon bimanual tasks and mobile manipulation in unstructured environments remains limited.
      </p>
      <p>
        To bridge this gap, we present RoboMIND 2.0, a comprehensive real-world dataset comprising over 310k dual-arm manipulation trajectories collected across six distinct robot embodiments and 739 complex tasks.
        Crucially, to support research in contact-rich and spatially extended tasks, the dataset incorporates 12k tactile-enhanced episodes and 20k mobile manipulation trajectories.
        Complementing this physical data, we construct high-fidelity digital twins of our real-world environments, releasing an additional 20k-trajectory simulated dataset to facilitate robust sim-to-real transfer.
      </p>
      <p>
        To fully exploit the potential of RoboMIND 2.0, we propose MIND-2 system, a hierarchical dual-system framework optimized via offline reinforcement learning.
        CoVLA integrates a high-level semantic planner (MIND-2-VLM) to decompose abstract natural language instructions into grounded subgoals, coupled with a low-level Vision-Language-Action executor (MIND-2-VLA), which generates precise, proprioception-aware motor actions.
        Extensive evaluations across six distinct robotic embodiments validate the effectiveness of our dataset and demonstrate that MIND-2 system significantly outperforms four single-task baselines (covering both 2D image and 3D point cloud modalities as well as four state-of-the-art VLA models).
        Furthermore, we observe that integrating tactile modalities yields measurable gains in fine-grained manipulation tasks.
      </p>
      <p>
        Finally, experimental results show that mixing real and simulated data during training consistently enhances physical execution performance, validating both the fidelity of our simulation benchmarks and the cost-efficiency of synthetic data augmentation.
        Our full dataset, simulation assets, and training code are publicly released to advance research in general-purpose robotic manipulation.
      </p>
    </div>

    <img src="./figs/teaser.png"></img>
    <p class="figure-caption">
      We introduce RoboMIND 2.0, a large-scale dataset comprising 310K
dual-arm trajectories collected from six heterogeneous robot embodiments, totaling over 1,000 hours. The dataset
features rich modalities, including 12K tactile-enriched sequences and 20K mobile manipulation trajectories. Collected
through a unified teleoperation and quality assurance pipeline, RoboMIND 2.0 ensures consistent proprioception and
provides fine-grained natural language annotations. To support scalable training and evaluation, we release digital-twin
USD assets and 20K simulation trajectories aligned with real-world tasks. Building on this foundation, we propose
MIND-2, a dual-system controller that integrates a slow high-level planner MIND-2-VLM with a fast low-level policy
MIND-2-VLA, enabling robust long-horizon mobile manipulation across diverse scenarios.
    </p>

    <div class="tagline" id="collection-platform">Collection Platform.</div>

    <div class="section">
      <div style="display: flex; justify-content: flex-start; margin: 16px 0;">
        <div style="width: min(500px, 60%); text-align: center;">
          <img src="./figs/franka.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Collection platform of Franka and UR5e.</b> Collect a robotic manipulation dataset by
            controlling the dual-arm system (Franka and UR5e) via HACTS.
          </p>
        </div>
      </div>

      <div style="display: flex; justify-content: flex-end; margin: 16px 0;">
        <div style="width: min(500px, 60%); text-align: center;">
          <img src="./figs/agilex.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Collection platform of AgileX and ARX.</b> We use a VR headset to control the ARK
            robot for data collection, and employ a slave arm to teleoperate the master arm for gathering the
            Agilex manipulation dataset.
          </p>
        </div>
      </div>

      <div style="display: flex; justify-content: flex-start; margin: 16px 0;">
        <div style="width: min(500px, 60%); text-align: center;">
          <img src="./figs/tianyi.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Collection platform of Tienkung and Tianyi.</b> For the humanoid robot TienKung, data collectors will
            wear motion capture suits to record joint movements, which are then mapped to the robot to enable
            robotic manipulation. For the dual-arm mobile robot with a wheeled base Tian Yi, we collected
            datasets using two human operators.
          </p>
        </div>
      </div>
    </div>

    <div class="tagline" id="realworld-setup">Real-world Setup.</div>
    <div class="section">
      <div style="display: flex; justify-content: center; margin: 16px 0;">
        <div style="width: min(900px, 92%); text-align: center;">
          <img src="./figs/robomindexpset.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Robotic real-world setup.</b> For the Franka and UR5e robots, we use cameras positioned
            at the top, left, and right viewpoints to record the visual information of the task trajectories. For the
            humanoid (Tien Kung and Tian Yi) robots, we use their built-in RGB-D cameras to capture visual
            observations. For the AgileX and ARX robots, we use dual wrist-mounted cameras (one on each
            arm) as well as a head-mounted camera to capture visual information.
          </p>
        </div>
      </div>
    </div>

    <!-- ===================== REAL-WORLD RESULTS: (Part1 demos excl. collab) + (Part2 result figure) ===================== -->
    <div class="tagline" id="realworld-results">Real-World Experiments.</div>
    <div class="section">

      <!-- Part 1: Real-world demos (excluding collaboration_training) -->

      <!-- franka_tasks -->
      <div class="video-gallery-section" id="demoFrankaTasksSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryFrankaTasks">
            <video class="gallery-video" src="./demos/franka_tasks_task1/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/franka_tasks_task2/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/franka_tasks_task3/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/franka_tasks_task4/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/franka_tasks_task5/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/franka_tasks_task6/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftFrankaTasks">&lt;</button>
            <button class="gallery-nav right" id="demoRightFrankaTasks">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Franka Tasks</b>
          </p>
        </div>
      </div>

      <!-- ur_training -->
      <div class="video-gallery-section" id="demoUrTrainingSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryUrTraining">
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_1/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_2/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_3/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_4/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_5/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ur_training_tasks_ur_training_task_6/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftUrTraining">&lt;</button>
            <button class="gallery-nav right" id="demoRightUrTraining">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>UR Tasks</b>
          </p>
        </div>
      </div>

      <!-- agilex_mob -->
      <div class="video-gallery-section" id="demoAgilexMobSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryAgilexMob">
            <video class="gallery-video" src="./demos/agilex_mob_training_tasks_agilex_arrange_dishes/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_mob_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_5_navigate_clean/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_mob_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_5_navigate_insert_tube/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_mob_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_5_navigate_move_to_plate/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftAgilexMob">&lt;</button>
            <button class="gallery-nav right" id="demoRightAgilexMob">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Agilex Mobile Manipulation Tasks</b>
          </p>
        </div>
      </div>

      <!-- agilex_training -->
      <div class="video-gallery-section" id="demoAgilexTrainingSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryAgilexTraining">
            <video class="gallery-video" src="./demos/agilex_training_tasks_agilex_2_make_sandwich/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_training_tasks_agilex_2_pour_meat_into_the_plate/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_2_assemble_PVC_drainage_pipe_clamps/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_2_make_sandwich_and_place_on_tray_250507/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_training_tasks_agilex_cobotmagic2_dualArm-gripper-3cameras_2_move_yellow_beetle_car_and_pick_and_place_it_into_the_blue_storage_box_20250430/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/agilex_training_tasks_gpt_agilex_cobotmagic2_dualArm-gripper-3cameras_2_sort_parts_20250527/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftAgilexTraining">&lt;</button>
            <button class="gallery-nav right" id="demoRightAgilexTraining">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Agilex Manipulation Tasks</b>
          </p>
        </div>
      </div>

      <!-- ark_training -->
      <div class="video-gallery-section" id="demoArkTrainingSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryArkTraining">
            <video class="gallery-video" src="./demos/ark_training_tasks_ark_02_collect_button/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ark_training_tasks_ark_03_insert_blue_toy_into_slot_250807/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ark_training_tasks_ark_1_dual_1_place_the_milk/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ark_training_tasks_ark_1_select_workpiece/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ark_training_tasks_ark_dual1_cross_move_apple_from_plate_to_bowl_250511/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/ark_training_tasks_gpt_ark_1_sort_fruits_250519/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftArkTraining">&lt;</button>
            <button class="gallery-nav right" id="demoRightArkTraining">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Ark Tasks</b>
          </p>
        </div>
      </div>

      <!-- tianyi_mob -->
      <div class="video-gallery-section" id="demoTianyiMobSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryTianyiMob">
            <video class="gallery-video" src="./demos/tianyi_mob_training_tasks_tienkung_prod2_dualArm-dexHand-1cameras_1_clean_the_dust/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tianyi_mob_training_tasks_tienkung_prod2_dualArm-dexHand-1cameras_1_Pick_and_Place_apple/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tianyi_mob_training_tasks_tienkung_prod2_dualArm-dexHand-1cameras_1_pick_and_place_onto_desktop/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tianyi_mob_training_tasks_tienkung_prod2_dualArm-dexHand-1cameras_1_pick_and_place_yellow_cube_in_box/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftTianyiMob">&lt;</button>
            <button class="gallery-nav right" id="demoRightTianyiMob">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Tianyi Tasks</b>
          </p>
        </div>
      </div>

      <!-- tienkung_training -->
      <div class="video-gallery-section" id="demoTienkungTrainingSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryTienkungTraining">
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_2_open_pot_lid/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_2_stack_the_cup/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_dualArm-gripper-1cameras_2_1_find_out_circuit_breaker_into_the_other_tray/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_dualArm-gripper-1cameras_2_pour_oil_for_gear/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_dualArm-gripper-1cameras_2_press_stop_button_of_control_box/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/tienkung_training_tasks_tienkung_pro2_dualArm-gripper-1cameras_2_sweep_electronic_rubbish/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftTienkungTraining">&lt;</button>
            <button class="gallery-nav right" id="demoRightTienkungTraining">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Tienkung Tasks</b>
          </p>
        </div>
      </div>

      <!-- Part 2: Existing real-world results figure -->
      <div style="display: flex; justify-content: center; margin: 16px 0;">
        <div style="width: min(980px, 96%); text-align: center;">
          <img src="./figs/table1.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            Performance comparison of single task imitation learning methods and VLA models
            across different task categories.
          </p>
        </div>
      </div>

    </div>
    <!-- ===================== END REAL-WORLD RESULTS ===================== -->

    <!-- ===================== DUAL SYSTEM EXPERIMENTS: Part1 collab demo + Part2 original figures ===================== -->
    <div class="tagline" id="dual-system-experiments">Dual System Experiments.</div>

    <div class="section">

      <!-- Part 1: Collaboration demo (moved here) -->
      <div class="video-gallery-section" id="demoDualTrainingSection">
        <div class="video-gallery-container">
          <div class="video-gallery" id="demoGalleryDualTraining">
            <video class="gallery-video" src="./demos/collab_mob_tasks_3/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/collab_mob_tasks_2/demo.mp4" autoplay muted playsinline loop></video>
            <video class="gallery-video" src="./demos/collab_mob_tasks_1/demo.mp4" autoplay muted playsinline loop></video>
          </div>
        </div>
        <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="demoLeftDualTraining">&lt;</button>
            <button class="gallery-nav right" id="demoRightDualTraining">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Dual-robot Collaborative Tasks</b>
          </p>
        </div>
      </div>

      <!-- Part 2: Original dual system figures -->
      <div style="display: flex; justify-content: center; margin: 16px 0;">
        <div style="width: min(980px, 96%); text-align: center;">
          <img src="./figs/table2.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Performance comparison across AgileX mobile manipulation tasks.</b> MIND-2 fast-slow system achieves significantly better
            performance across various tasks compared to both VLA models and single-task imitation learning
            methods
          </p>
        </div>
      </div>

      <div style="display: flex; justify-content: center; margin: 16px 0;">
        <div style="width: min(980px, 96%); text-align: center;">
          <img src="./figs/table3.png" style="width: 100%; height: auto; border-radius: 10px;" />
          <p class="figure-caption" style="text-align: left; margin-top: 10px;">
            <b>Success rates across three collaborative tasks.</b>
            MIND-2 (Post Training) is instantiated by fine-tuning InternVL3 and pi0.5 directly on data from the three multi-robot collaboration tasks.
            MIND-2 (Full-scale Training) is first pretrained on the full-scale mobile manipulation dataset using a fast-slow system architecture, and then further fine-tuned via post-training on data from three multi-robot collaboration tasks.
            MIND-2 (Offline RL), after full-scale training, we apply Implicit Q-Learning (IQL) to conduct offline reinforcement learning on the MIND-2-VLA.
          </p>
        </div>
      </div>

    </div>
    <!-- ===================== END DUAL SYSTEM EXPERIMENTS ===================== -->

    <div class="bibtex-code">
      <div class="bibtex-title">BibTeX</div>
      <pre><code>@misc{hou2025robomind20multimodalbimanual,
      title={RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence}, 
      author={Chengkai Hou and Kun Wu and Jiaming Liu and Zhengping Che and Di Wu and Fei Liao and Guangrun Li and Jingyang He and Qiuxuan Feng and Zhao Jin and Chenyang Gu and Zhuoyang Liu and Nuowei Han and Xiangju Mi and Yaoxu Lv and Yankai Fu and Gaole Dai and Langzhe Gu and Tao Li and Yuheng Zhang and Yixue Zhang and Xinhua Wang and Shichao Fan and Meng Li and Zhen Zhao and Ning Liu and Zhiyuan Xu and Pei Ren and Junjie Ji and Haonan Liu and Kuan Cheng and Shanghang Zhang and Jian Tang},
      year={2025},
      eprint={2512.24653},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.24653}, 
}</code></pre>
    </div>

  </div> <!-- End of main-content div -->

  <!-- <div class="footer">
     © Shanghai Qi Zhi Institute | Webpage template from <a href="https://www.videomimic.net/">VideoMimic</a>.
  </div> -->

  <!-- Teaser Video Autoplay with Delay and Loop (video is commented out, so harmless) -->
  <script>
  document.addEventListener('DOMContentLoaded', function() {
    const video = document.getElementById('teaser-video');
    const loopDelay = 3000;
    let loopTimeout;

    if (video) {
      video.muted = true;

      video.addEventListener('ended', function() {
        clearTimeout(loopTimeout);
        loopTimeout = setTimeout(function() {
          video.currentTime = 0;
          video.play().catch(function(error) {
            console.log('Delayed loop play prevented for teaser video:', error);
          });
        }, loopDelay);
      });

      video.addEventListener('pause', function() {
        if (!video.ended && video.currentTime > 0) {
           clearTimeout(loopTimeout);
        }
      });
    }
  });
  </script>

  <!-- JavaScript for Video Gallery Navigation (original) -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const galleries = [
        { sectionId: 'gallery-section-anchor', galleryInnerId: 'videoGallerySitting', scrollLeftBtnId: 'scrollLeftBtnSitting', scrollRightBtnId: 'scrollRightBtnSitting' },
        { sectionId: 'traversingGallerySection', galleryInnerId: 'videoGalleryTraversing', scrollLeftBtnId: 'scrollLeftBtnTraversing', scrollRightBtnId: 'scrollRightBtnTraversing' },
        { sectionId: 'stairsGallerySection', galleryInnerId: 'videoGalleryStairs', scrollLeftBtnId: 'scrollLeftBtnStairs', scrollRightBtnId: 'scrollRightBtnStairs' },
        { sectionId: 'reconstructionGallerySection', galleryInnerId: 'videoGalleryReconstruction', scrollLeftBtnId: 'scrollLeftBtnReconstruction', scrollRightBtnId: 'scrollRightBtnReconstruction' }
      ];

      galleries.forEach(galleryConfig => {
        const gallerySection = document.getElementById(galleryConfig.sectionId);
        if (!gallerySection) return;

        const galleryContainer = gallerySection.querySelector('.video-gallery-container');
        const galleryInner = document.getElementById(galleryConfig.galleryInnerId);
        const scrollLeftBtn = document.getElementById(galleryConfig.scrollLeftBtnId);
        const scrollRightBtn = document.getElementById(galleryConfig.scrollRightBtnId);

        if (galleryContainer && galleryInner && scrollLeftBtn && scrollRightBtn) {
          const scrollAmount = (galleryInner.firstElementChild?.offsetWidth || 300) + 15;
          scrollLeftBtn.addEventListener('click', () => galleryContainer.scrollBy({ left: -scrollAmount, behavior: 'smooth' }));
          scrollRightBtn.addEventListener('click', () => galleryContainer.scrollBy({ left: scrollAmount, behavior: 'smooth' }));
        }
      });
    });
  </script>

  <!-- Navigation for demo galleries (now used by realworld-results + dual-system-experiments) -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const demoGalleries = [
        { sectionId: 'demoAgilexMobSection', galleryInnerId: 'demoGalleryAgilexMob', leftId: 'demoLeftAgilexMob', rightId: 'demoRightAgilexMob' },
        { sectionId: 'demoAgilexTrainingSection', galleryInnerId: 'demoGalleryAgilexTraining', leftId: 'demoLeftAgilexTraining', rightId: 'demoRightAgilexTraining' },
        { sectionId: 'demoArkTrainingSection', galleryInnerId: 'demoGalleryArkTraining', leftId: 'demoLeftArkTraining', rightId: 'demoRightArkTraining' },
        { sectionId: 'demoFrankaTasksSection', galleryInnerId: 'demoGalleryFrankaTasks', leftId: 'demoLeftFrankaTasks', rightId: 'demoRightFrankaTasks' },
        { sectionId: 'demoTianyiMobSection', galleryInnerId: 'demoGalleryTianyiMob', leftId: 'demoLeftTianyiMob', rightId: 'demoRightTianyiMob' },
        { sectionId: 'demoTienkungTrainingSection', galleryInnerId: 'demoGalleryTienkungTraining', leftId: 'demoLeftTienkungTraining', rightId: 'demoRightTienkungTraining' },
        { sectionId: 'demoUrTrainingSection', galleryInnerId: 'demoGalleryUrTraining', leftId: 'demoLeftUrTraining', rightId: 'demoRightUrTraining' },
        { sectionId: 'demoDualTrainingSection', galleryInnerId: 'demoGalleryDualTraining', leftId: 'demoLeftDualTraining', rightId: 'demoRightDualTraining' },
      ];

      demoGalleries.forEach(cfg => {
        const section = document.getElementById(cfg.sectionId);
        if (!section) return;

        const container = section.querySelector('.video-gallery-container');
        const inner = document.getElementById(cfg.galleryInnerId);
        const leftBtn = document.getElementById(cfg.leftId);
        const rightBtn = document.getElementById(cfg.rightId);

        if (!container || !inner || !leftBtn || !rightBtn) return;

        const scrollAmount = (inner.firstElementChild?.offsetWidth || 300) + 15;
        leftBtn.addEventListener('click', () => container.scrollBy({ left: -scrollAmount, behavior: 'smooth' }));
        rightBtn.addEventListener('click', () => container.scrollBy({ left:  scrollAmount, behavior: 'smooth' }));
      });
    });
  </script>

  <!-- JavaScript for Real-to-Sim Video Synchronization -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const videosToSync = [
        document.querySelector('.r2s-video-input'),
        document.querySelector('.r2s-video-smpl'),
        document.querySelector('.r2s-video-g1'),
        document.querySelector('.r2s-video-ego-rgb'),
        document.querySelector('.r2s-video-ego-depth'),
        document.querySelector('.r2s-video-sim')
      ].filter(Boolean);

      function synchronizeAndPlayR2SVideos() {
        if (videosToSync.length === 0) return;

        const readyPromises = videosToSync.map(video => new Promise((resolve, reject) => {
          if (video.readyState >= 4) resolve();
          else {
            video.addEventListener('canplaythrough', resolve, { once: true });
            video.addEventListener('error', reject, { once: true });
          }
        }));

        Promise.all(readyPromises).then(() => {
          videosToSync.forEach(video => {
            video.currentTime = 0;
            video.play().catch(() => { video.controls = true; });
          });
        }).catch(() => {
          videosToSync.forEach(video => video.controls = true);
        });
      }

      synchronizeAndPlayR2SVideos();
    });
  </script>

  <!-- JavaScript to prevent default click on specific image links -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const imageLinkIds = ['figure-1-img', 'figure-2-img', 'figure-3-img'];
      imageLinkIds.forEach(id => {
        const linkElement = document.getElementById(id);
        if (linkElement) linkElement.addEventListener('click', e => e.preventDefault());
      });
    });
  </script>

</body>
</html>