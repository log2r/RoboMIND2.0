<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>FVP</title>
  <link rel="icon" href="./figs/logo.jpg" type="image/png">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="toc">
    <h3>Content</h3>
    <hr>
    <ul>
      <li><a href="#abstract">Abstract</a></li>
      <li><a href="#deploy-in-real">Real-world Demo</a></li>
      <li><a href="#approach">Approach</a></li>
      <li><a href="#approach">Real-World Results</a></li>
      <li><a href="#approach">Visualizing the Diffusion Process of Dexterous Hand Tasks</a></li>
      <li><a href="#approach">Enhancing Effect of FVP on VLA Model Tasks</a></li>
      <!-- <li class="toc-subsection"><a href="#training-in-sim">Training in Sim</a></li> -->
    </ul>
  </div>

  <div class="main-content">
    <div class="hero-text" style="font-size: 100px; text-align: center; margin-bottom: -10px;">FVP</div>
    <div class="sub-hero-text" style="text-align: center;">4D Visual Pre-training for Robot Learning</div>

    
    <!-- add authors -->
    <div class="authors" style="text-align: center; color: #000000;">
      <span class="author-block" style="font-weight: bold;"><a href="https://jackhck.github.io">Chengkai Hou</a><sup>1</sup> <a href="https://yanjieze.com">Yanjie Ze</a><sup>3</sup> Yankai Fu</a><sup>1</sup>
      Zeyu Gao</a><sup>4</sup> <a href="">Yue Yu</a><sup>2</sup> <a href="">Songbo Hu</a><sup>2</sup> 
      <a href="https://www.shanghangzhang.com">Shanghang Zhang</a><sup>1</sup> <a href="http://hxu.rocks/index.html">Huazhe Xu</a><sup>235</sup></span>
      <span class="affiliation" style="font-weight: normal;"><sup>1</sup>Peking University <sup>2</sup>Tsinghua University <sup>3</sup>Shanghai Qizhi Institute <sup>4</sup>CASIA <sup>5</sup>Shanghai AI Lab</span>
      <br>
      <div class="affiliation" style="text-align: center; margin-bottom: 10px; margin-top: -10px;">Accepted by ICCV 2025</div>
    </div>





    <!-- use the video ./figs/videomimic_teaser.mp4 -->
    <video id="teaser-video" src="./static/videos/teaser.mp4" width="100%" height="100%" controls muted playsinline autoplay></video>
    <p class="figure-caption">
      <span style="font-variant: small-caps;">FVP</span> is a novel 3D point cloud representation learning pipeline for robotic manipulation.
  </p>

    <div class="links-block">
      <a href="https://arxiv.org/pdf/2508.17230" target="_blank">[<strong>pdf</strong>]</a>
      <a href="https://arxiv.org/abs/2508.17230" target="_blank">[<strong>arxiv</strong>]</a>
      <a href="" target="_blank">[<strong>code(soon)</strong>]</a>
    </div>

    
    <div class="tagline" id="abstract">Abstract.</div>


    <div class="section">
      <p>
        General visual representations learned from web-scale datasets for robotics have achieved great success in recent years, enabling data-efficient robot learning on manipulation tasks;
      </p>
      <p>
       yet these pre-trained representations are mostly on 2D images, neglecting the inherent 3D nature of the world. However, due to the scarcity of large-scale 3D data, it is still hard to extract a universal 3D representation from web datasets. Instead, we seek for a general visual pre-training framework that could improve all 3D representations as an alternative. Our framework, called <b> FVP </b>, is a novel 4D Visual Pre-training framework for real-world robot learning. FVP frames the visual pre-training objective as a next-point-cloud-prediction problem, models the prediction model as a diffusion model, and pre-trains the model on in-domain task datasets directly. 
      </p>
      <p>
       Across twelve real-world manipulation tasks, FVP boosts the average success rate of 3D Diffusion Policy (DP3) for these tasks by 28\%. The FVP pre-trained DP3 achieves state-of-the-art performance across imitation learning methods. Moreover, the efficacy of FVP adapts across various point cloud encoders and datasets. 
      Finally, we apply FVP to the RDT-1B, a larger Vision-Language-Action robotic model, enhancing its performance on various robot tasks.
      
    </div> 
    <img src="./figs/teaser.png"></img>
    <!-- Caption for Figure 1 (Teaser Video) -->
    <p class="figure-caption">
        Different from prior works in Contrastive Learning, Masked Signal Modeling; FVP trains 3D visual representations by leveraging the preceding frame point cloud and employing a diffusion model to predict the point cloud of the current frame.
    </p>

    <div class="tagline" id="deploy-in-real">Real-world Demo.</div>

    <!-- Video Gallery Section - STAIRS VIDEOS -->
    <div class="video-gallery-section" id="stairsGallerySection">
      <div class="video-gallery-container">
        <div class="video-gallery" id="videoGalleryStairs">
          <!-- Videos remain here - ADD autoplay -->
          <img class="gallery-video" src="./static/images/head.jpg" autoplay muted playsinline loop></img>
          <video class="gallery-video" src="./static/videos/artimanip.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/videos/assembly.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/videos/chicken.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/videos/flipcup.mp4" autoplay muted playsinline loop></video>
          <!-- Add more videos as needed, ensuring they have autoplay muted loop -->
        </div>
      </div>
      <!-- Container for the caption AND buttons -->
      <div class="gallery-caption-container">
          <!-- Move button controls INSIDE caption container -->
          <div class="gallery-nav-controls">
              <button class="gallery-nav left" id="scrollLeftBtnStairs">&lt;</button>
              <button class="gallery-nav right" id="scrollRightBtnStairs">&gt;</button>
          </div>
          <!-- Caption text -->
          <p class="figure-caption gallery-caption">
              <b>UR5 Dexterous Hand:</b> UR5 single-arm is equipped with a LeapHand dexterous hand to complete four tasks: PickPlace, FlipCup, Assembly, Artimanip.
          </p>
      </div>
    </div>
  <!-- End Video Gallery Section -->

  <!-- Video Gallery Section - SITTING VIDEOS -->
  <div class="video-gallery-section" id="gallery-section-anchor">
    <div class="video-gallery-container">
      <div class="video-gallery" id="videoGallerySitting">
        <!-- Videos remain here - ADD autoplay -->
        <img class="gallery-video" src="./static/images/dual.jpg" autoplay muted playsinline loop></img>
        <video class="gallery-video" src="./static/videos/dual_fruit.mp4" autoplay muted playsinline loop></video>
        <video class="gallery-video" src="./static/videos/dual_cup.mp4" autoplay muted playsinline loop></video>
        <video class="gallery-video" src="./static/videos/dual_wish.mp4" autoplay muted playsinline loop></video>
        <!-- Add more videos as needed, ensuring they have autoplay muted loop -->
      </div>
    </div>
    <!-- Container for the caption AND buttons -->
    <div class="gallery-caption-container">
        <!-- Move button controls INSIDE caption container -->
        <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="scrollLeftBtnSitting">&lt;</button>
            <button class="gallery-nav right" id="scrollRightBtnSitting">&gt;</button>
        </div>
        <!-- Caption text -->
        <p class="figure-caption gallery-caption">
            <b>AgileX Dual-arm:</b> We use the AgileX Cobot Magic dual-arm robot to perform the three manipulation tasks: PutBox, StackBowl, WipePlate.
        </p>
    </div>
  </div>
  <!-- End Video Gallery Section -->

  <!-- Video Gallery Section - TRAVERSING VIDEOS -->
    <div class="video-gallery-section" id="traversingGallerySection">
      <div class="video-gallery-container">
        <div class="video-gallery" id="videoGalleryTraversing">
          <!-- Videos remain here - ADD autoplay -->
          <img class="gallery-video" src="./static/images/human.jpg" autoplay muted playsinline loop></img>
          <video class="gallery-video" src="./static/videos/closedrawer.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/videos/bread.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/videos/closeclip.mp4" autoplay muted playsinline loop></video>
          <!-- Add more videos as needed, ensuring they have autoplay muted loop -->
        </div>
      </div>
      <!-- Container for the caption AND buttons -->
      <div class="gallery-caption-container">
          <!-- Move button controls INSIDE caption container -->
          <div class="gallery-nav-controls">
              <button class="gallery-nav left" id="scrollLeftBtnTraversing">&lt;</button>
              <button class="gallery-nav right" id="scrollRightBtnTraversing">&gt;</button>
          </div>
          <!-- Caption text -->
          <p class="figure-caption gallery-caption">
              <b>TianGong Humanoid:</b> We use the TianGong humanoid robot, equipped with built-in cameras and a 30-DoF upper body, to perform three real-world tasks: PushDraw, ToastBread, CloseLid.
          </p>
      </div>
    </div>
  <!-- End Video Gallery Section -->
    <div class="tagline" id="approach">Approach.</div>

    <div class="r2s-vertical-layout">
      <div class="r2s-video-row r2s-top-row">
        <img class="r2s-video-item r2s-video-input" src="./static/images/me.png" autoplay muted loop playsinline></img>
      </div>
      <div class="r2s-caption-row">
        <p class="r2s-caption-item">Model Overview</p>
      </div>
      <p class="figure-caption">
        <b>FVP mainly consists of two parts: a 3D visual encoder and a point cloud diffusion model. The 3D visual encoder transforms the point cloud
          at time step t into the latent visual representation, and the diffusion model uses the latent visual
          representation and robotic actions to predict the point cloud at step time t+1. During the policy
          learning stage, we train the pre-trained visual model and the policy backbone jointly.</b>
      </p>
    </div>

    <div class="tagline" id="approach">Real-World Results.</div>

    <div class="r2s-vertical-layout">
      <div class="r2s-video-row r2s-top-row">
        <img class="r2s-video-item r2s-video-input" src="./static/images/realworld.png" autoplay muted loop playsinline></img>
      </div>
      <p class="figure-caption">
        <b>"DP3+FVP" and "RISE+FVP" denote the application of FVP to pretrain the visual models from DP3 and RISE,
          respectively. "DP3" indicates that the visual model within DP3 has not undergone pretraining. "DP3+PointMAE", "DP3+STRL", and
   "DP3+C2P" signify the utilization of PointMAE, STRL, and C2P to pre-train the visual model from DP3. The numbers before the comma
   represent the performance using in-domain datasets for pre-training, while the numbers after the comma represent the performance using
   out-of-domain datasets (RoboMind) for pre-training.</b>
      </p>
    </div>

    <div class="tagline" id="approach">Visualizing the Diffusion Process of Dexterous Hand Tasks.</div>
    <!-- Row 1 -->
    <div class="video-gallery-container">
      <div class="video-gallery" id="videoGallerySitting">
          <video class="gallery-video" src="./static/gif/output/chicken5.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/chicken20.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/chicken110.mp4" autoplay muted playsinline loop></video>
      </div>
    </div>

    <!-- Row 2 -->
    <div class="video-gallery-container">
      <div class="video-gallery" id="videoGallerySitting">
          <video class="gallery-video" src="./static/gif/output/cap5.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/cap20.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/cap105.mp4" autoplay muted playsinline loop></video>
      </div>
    </div>

    <!-- Row 3 -->
    <div class="video-gallery-container">
      <div class="video-gallery" id="videoGallerySitting">
          <video class="gallery-video" src="./static/gif/output/assembly5.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/assembly35.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/assembly65.mp4" autoplay muted playsinline loop></video>
      </div>
    </div>

    <!-- Row 4 -->
    <div class="video-gallery-container">
      <div class="video-gallery" id="videoGallerySitting">
          <video class="gallery-video" src="./static/gif/output/articulate5.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/articulate35.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./static/gif/output/articulate65.mp4" autoplay muted playsinline loop></video>
      </div>
    </div>
    
    <div class="tagline" id="approach">Enhancing Effect of FVP on VLA Model Tasks.</div>

    <!-- Task 1 -->
    <div class="video-gallery-container">
      <h2 class="video-gallery-title">PutBox</h2>
      <div class="video-gallery" id="videoGallerySitting">
        <div class="video-item">
          <h3 class="video-title">RDT</h3>
          <video class="gallery-video" src="./static/videos/dp_fr_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div style="width: 40px;"></div>
        <div class="video-item">
          <h3 class="video-title">RDT+FVP</h3>
          <video class="gallery-video" src="./static/videos/dp_fr_2.mp4" autoplay muted loop playsinline></video>
        </div>
      </div>
    </div>

    <!-- Task 2 -->
    <div class="video-gallery-container">
      <h2 class="video-gallery-title">StackBowl</h2>
      <div class="video-gallery" id="videoGallerySitting">
        <div class="video-item">
          <h3 class="video-title">RDT</h3>
          <video class="gallery-video" src="./static/videos/dp_wp_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div style="width: 40px;"></div>
        <div class="video-item">
          <h3 class="video-title">RDT+FVP</h3>
          <video class="gallery-video" src="./static/videos/dp_wp_2.mp4" autoplay muted loop playsinline></video>
        </div>
      </div>
    </div>

    <!-- Task 3 -->
    <div class="video-gallery-container">
      <h2 class="video-gallery-title">WipePlate</h2>
      <div class="video-gallery" id="videoGallerySitting">
        <div class="video-item">
          <h3 class="video-title">RDT</h3>
          <video class="gallery-video" src="./static/videos/dp_wh_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div style="width: 40px;"></div>
        <div class="video-item">
          <h3 class="video-title">RDT+FVP</h3>
          <video class="gallery-video" src="./static/videos/dp_wh_2.mp4" autoplay muted loop playsinline></video>
        </div>
      </div>
    </div>

    <!-- Task 4 -->
    <div class="video-gallery-container">
      <h2 class="video-gallery-title">Long-horizon Task</h2>
      <div class="video-gallery" id="videoGallerySitting">
        <div class="video-item">
          <h3 class="video-title">RDT</h3>
          <video class="gallery-video" src="./static/videos/dp_lr_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div style="width: 40px;"></div>
        <div class="video-item">
          <h3 class="video-title">RDT+FVP</h3>
          <video class="gallery-video" src="./static/videos/dp_lr_2.mp4" autoplay muted loop playsinline></video>
        </div>
      </div>
    </div>

  <div class="bibtex-code">
    <div class="bibtex-title">BibTeX</div>
    <pre><code>@article{cheng2025fvp,
    author    = {Chengkai Hou and Yanjie Ze and Yankai Fu and Zeyu Gao and Yue Yu and Songbo Hu and Shanghang Zhang and Huazhe Xu},
    title     = {FVP: 4D Visual Pre-training for Robot Learning},
    journal   = {ICCV},
    year      = {2025},
  }</code></pre>
  </div>
  </div> <!-- End of main-content div -->


  <div class="footer">
     Â© Shanghai Qi Zhi Institute | Webpage template from <a href="https://www.videomimic.net/">VideoMimic</a>.
  </div>

  <!-- Teaser Video Autoplay with Delay and Loop -->
  <script>
  document.addEventListener('DOMContentLoaded', function() {
    const video = document.getElementById('teaser-video');
    // const initialDelay = 1000; // No longer needed, autoplay attribute handles initial play
    const loopDelay = 3000;    // 3 seconds delay before looping

    // let initialPlayTimeout; // No longer needed
    let loopTimeout;

    if (video) {
      // Ensure video is muted (already in HTML, but good practice)
      video.muted = true;
      // Controls are already in HTML, ensuring user can play if autoplay fails

      // REMOVE JavaScript-based initial play:
      /*
      initialPlayTimeout = setTimeout(function() {
        video.play().then(function() {
          // Autoplay started
        }).catch(function(error) {
          console.log('Initial autoplay prevented for teaser video. User interaction might be needed.', error);
          video.controls = true; // Ensure controls are visible
        });
      }, initialDelay);
      */

      // Loop with delay - this part can stay
      video.addEventListener('ended', function() {
        clearTimeout(loopTimeout); 
        loopTimeout = setTimeout(function() {
          video.currentTime = 0; 
          video.play().catch(function(error) {
            console.log('Delayed loop play prevented for teaser video:', error);
          });
        }, loopDelay);
      });

      // --- Clear Timeouts on Manual Pause ---
      video.addEventListener('pause', function() {
        if (!video.ended && video.currentTime > 0) {
           // clearTimeout(initialPlayTimeout); // No longer needed
           clearTimeout(loopTimeout);
           console.log('Teaser video: Manual pause detected, clearing loop timeout.');
        }
      });

      // --- Clear Timeouts on Manual Play (if paused before initial delay finishes) ---
       video.addEventListener('play', function() {
           // if (initialPlayTimeout) { // No longer needed
           //     clearTimeout(initialPlayTimeout);
           // }
       });

    } else {
      console.error('Video element with ID "teaser-video" not found.');
    }
  });
  </script>

  <!-- JavaScript for Video Gallery Navigation -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const galleries = [
        {
          sectionId: 'gallery-section-anchor', // ID of the .video-gallery-section for sitting
          galleryInnerId: 'videoGallerySitting',
          scrollLeftBtnId: 'scrollLeftBtnSitting',
          scrollRightBtnId: 'scrollRightBtnSitting'
        },
        {
          sectionId: 'traversingGallerySection', // ID of the .video-gallery-section for traversing
          galleryInnerId: 'videoGalleryTraversing',
          scrollLeftBtnId: 'scrollLeftBtnTraversing',
          scrollRightBtnId: 'scrollRightBtnTraversing'
        },
        {
          sectionId: 'stairsGallerySection', // ID of the .video-gallery-section for stairs
          galleryInnerId: 'videoGalleryStairs',
          scrollLeftBtnId: 'scrollLeftBtnStairs',
          scrollRightBtnId: 'scrollRightBtnStairs'
        },
        {
          sectionId: 'reconstructionGallerySection', // ID of the .video-gallery-section for reconstruction
          galleryInnerId: 'videoGalleryReconstruction',
          scrollLeftBtnId: 'scrollLeftBtnReconstruction',
          scrollRightBtnId: 'scrollRightBtnReconstruction'
        }
      ];

      galleries.forEach(galleryConfig => {
        const gallerySection = document.getElementById(galleryConfig.sectionId);
        if (!gallerySection) {
          console.error(`Gallery section with ID ${galleryConfig.sectionId} not found.`);
          return;
        }

        const galleryContainer = gallerySection.querySelector('.video-gallery-container');
        const galleryInner = document.getElementById(galleryConfig.galleryInnerId);
        const scrollLeftBtn = document.getElementById(galleryConfig.scrollLeftBtnId);
        const scrollRightBtn = document.getElementById(galleryConfig.scrollRightBtnId);

        if (galleryContainer && galleryInner && scrollLeftBtn && scrollRightBtn) {
          // Calculate the scroll amount based on the width of the first video + gap
          const scrollAmount = (galleryInner.firstElementChild?.offsetWidth || 300) + 15; // 15 is the gap

          scrollLeftBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: -scrollAmount, behavior: 'smooth' });
          });

          scrollRightBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: scrollAmount, behavior: 'smooth' });
          });

          /* --- REMOVE OR COMMENT OUT HOVER LOGIC ---
          // Optional: Add hover-to-play functionality for gallery videos
          // Target videos within galleryInner
          const galleryVideos = galleryInner.querySelectorAll('.gallery-video');
          galleryVideos.forEach(video => {
              video.addEventListener('mouseenter', () => {
                  video.play().catch(e => console.log("Autoplay prevented:", e));
              });
              video.addEventListener('mouseleave', () => {
                  video.pause();
                  // video.currentTime = 0; // Optional: reset video on mouse leave
              });
          });
          */ // --- END OF REMOVED HOVER LOGIC ---

        } else {
          console.error(`Gallery elements not found for navigation setup in section ${galleryConfig.sectionId}.`);
          // Log which elements might be missing
          if (!galleryContainer) console.error('Missing element: .video-gallery-container in section ' + galleryConfig.sectionId);
          if (!galleryInner) console.error(`Missing element with ID ${galleryConfig.galleryInnerId}`);
          if (!scrollLeftBtn) console.error(`Missing element with ID ${galleryConfig.scrollLeftBtnId}`);
          if (!scrollRightBtn) console.error(`Missing element with ID ${galleryConfig.scrollRightBtnId}`);
        }
      });
    });
  </script>

  <!-- JavaScript for Real-to-Sim Video Synchronization -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const videosToSync = [
        document.querySelector('.r2s-video-input'),
        document.querySelector('.r2s-video-smpl'),
        document.querySelector('.r2s-video-g1'),
        document.querySelector('.r2s-video-ego-rgb'),
        document.querySelector('.r2s-video-ego-depth'),
        document.querySelector('.r2s-video-sim')
      ].filter(Boolean); // Filter out nulls if any class name is wrong or video missing

      function synchronizeAndPlayR2SVideos() {
        if (videosToSync.length === 0) {
          console.warn('No videos found for Real-to-Sim synchronization.');
          return;
        }

        const readyPromises = videosToSync.map(video => {
          return new Promise((resolve, reject) => {
            // If video is already ready (e.g., cached), resolve immediately
            if (video.readyState >= 4) { // HAVE_ENOUGH_DATA (canplaythrough)
              resolve();
            } else {
              video.addEventListener('canplaythrough', resolve, { once: true });
              video.addEventListener('error', reject, { once: true }); // Handle potential loading errors
            }
          });
        });

        Promise.all(readyPromises)
          .then(() => {
            console.log('All Real-to-Sim videos are ready to play. Starting playback.');
            videosToSync.forEach(video => {
              video.currentTime = 0; // Ensure starting from the beginning
              video.play().catch(error => {
                console.warn(`Autoplay was prevented for video ${video.src}. User interaction might be needed.`, error);
                // Ensure controls are visible if autoplay fails for any video
                video.controls = true;
              });
            });
          })
          .catch(error => {
            console.error('Error waiting for Real-to-Sim videos to be ready:', error);
            // Optionally, provide a fallback or user message here
            videosToSync.forEach(video => video.controls = true); // Show controls on all if any failed to load
          });
      }

      synchronizeAndPlayR2SVideos();

      // The `loop` attribute on the HTML video tags will handle continuous looping.
      // The videos will naturally re-synchronize at their LCM due to the loop attribute
      // if they have different durations and all successfully start.
    });
  </script>

  <!-- JavaScript to prevent default click on specific image links -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const imageLinkIds = ['figure-1-img', 'figure-2-img', 'figure-3-img'];
      imageLinkIds.forEach(id => {
        const linkElement = document.getElementById(id);
        if (linkElement) {
          linkElement.addEventListener('click', function(event) {
            event.preventDefault();
          });
        }
      });
    });
  </script>

</body>
</html>
